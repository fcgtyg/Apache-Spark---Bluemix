{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "from pyspark.ml.feature import HashingTF, Tokenizer, CountVectorizer\n\ntokenizer = Tokenizer(inputCol=\"data\", outputCol=\"words\")\nvectorize = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n\n", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "a = sqlContext.createDataFrame(reviewsRdd.map(lambda x: Row(data=x)))\ngg = tokenizer.transform(a).cache()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "vectorModel = vectorize.fit(gg)\ngg2 = vectorModel.transform(gg)\ngg2.cache()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "DataFrame[data: string, words: array<string>, features: vector]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 4, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "lda = LDA(k=2)\nmodel = lda.fit(gg2)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "topics = model.topicsMatrix()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "topicDesc = model.describeTopics(6)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "wordSpace = vectorModel.vocabulary", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "allTopicDesc = topicDesc.rdd.map(tuple).collect()\nallTopicDesc", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[(0,\n  [46, 208, 241, 283, 329, 348],\n  [0.007013673374518493,\n   0.002771985430113241,\n   0.0025684859111648195,\n   0.0022770414954440725,\n   0.002040774192488661,\n   0.001941786342656618]),\n (1,\n  [0, 1, 2, 3, 4, 5],\n  [0.008423638428329935,\n   0.00677888032386952,\n   0.005761973739242475,\n   0.003814912979951051,\n   0.00371611259041432,\n   0.003462090037384256])]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 9, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "result = {}\nfor topic in allTopicDesc:\n    decodedWords = []\n    for code in topic[1]:\n        decodedWords.append(wordSpace[code])\n    result[\"Topic%d\" %topic[0]] = decodedWords\n\nresult\n    ", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'Topic0': [u'nicht', u'einen', u'essen', u'waren', u'einem', u'etwas'],\n 'Topic1': [u'place', u'great', u'really', u'service', u'always', u'little']}"
                    }, 
                    "metadata": {}, 
                    "execution_count": 10, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 0
}